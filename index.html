<html>
<!-- PLEASE CREDIT https://prashnani.github.io if using this template. See the end of this document to know how. -->
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">	 
  	<meta name="description" content="Ekta Prashnani Homepage">
  	<meta name="keywords" content="Ekta Prashnani">
  	<meta name="author" content="Ekta Prashnani">
  	<meta name="viewport" content="width=device-width, initial-scale=1.0">	
	<title>Ekta Prashnani Homepage </title>
	<style type="text/css"></style>
</head>

<body>
	<table border="0" width="50%" align="center" style="max-width:100%">
	<tbody><tr><td></td><td valign="top">

        <br>
        <table style="font-size: 13pt;" border="0" width="100%" bgcolor="F5F5F5">
            <tbody><tr>
                <td width="50%" align="center">                    
                    <img width="200" src="index_files/profile.jpg" border="5%" style="border-color:transparent" >
                </td>
                <td align="left">
                    <font face= "Century Gothic, CenturyGothic, AppleGothic, sans-serif" size="6"> 
                        Ekta Prashnani<br>
                    </font>
                    <font face="Century Gothic, CenturyGothic, AppleGothic, sans-serif" size="4"> 
                        Ph.D. Candidate (Computer Vision) <br>
                        University of California<br>
                        Santa Barbara, CA<br><br>
                        ekta at ece dot ucsb dot edu<br>
                        [<a href="https://github.com/prashnani" border="0" style="color:528B8B">GitHub</a>]
                        [<a href="https://scholar.google.com/citations?user=na-Ba1EAAAAJ&hl=en" border="0" style="color:528B8B">Google Scholar</a>]
						[<a href="https://prashnani.github.io/index_files/Ekta_Prashnani_CV_Nov2021.pdf" border="0" style="color:528B8B">CV</a>]<br>
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <br>
        <p>
       
        <font style="font-size: 13pt;" face="Century Gothic, CenturyGothic, AppleGothic, sans-serif" > 
		
		For my Ph.D. research, I work on designing robust deep-learning algorithms for subjective perceptual tasks such as perceptually-consistent image error prediction, video saliency prediction.
		I find these problems particularly exciting because the subjective nature of these tasks and, in some cases, the difficulty in capturing sufficient training data poses an interesting challenge in terms of training with limited / noisy data.
		I am also interested in the research problems around the topics of understanding and tuning the latent space of deep generative models, and image / video forensics.
		A <a href="https://arxiv.org/abs/2104.08038" style="color:528B8B" target="_blank">preprint</a> of our recent work on noise-aware training for visual saliency prediction can be found on arXiv.
		Our <a href="https://arxiv.org/abs/1806.02067" style="color:528B8B" target="_blank">CVPR 2018 paper</a> provides details of a perceptually consistent image error metric. The accompanying code, models, and datasets can be found at the <a href="https://github.com/prashnani/PerceptualImageError" style="color:528B8B" target="_blank">GitHub repository</a>.		
		<br>
		<br>
		My time in grad school is split between my own research and providing <a href="#teaching" style="color:528B8B">technical mentorship </a>
		(which I thoroughly enjoy!) to senior undergrads and even high-school students for their research in computer vision and machine learning. 
		I also enjoy running long distances, 
		painting and <a href="https://www.flickr.com/photos/133729196@N03/" style="color:528B8B" target="_blank">taking pictures</a>.
		</font>

        </p><hr size="1" align="left" color="c3c3c3">     		
		<font face= "Century Gothic, CenturyGothic, AppleGothic, sans-serif" style="font-size: 22pt;"> News
        <table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody>
				<tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">Jun, 2021: ECE Dissertation Fellowship by the Department of Electrical and Computer Engineering, UCSB, for Summer 2021.</td></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">Apr, 2021: A preprint of our work on noise-aware training strategies for visual saliency prediction (in particular, video saliency prediction) is now available on <a href="https://arxiv.org/abs/2104.08038" style="color:528B8B" target="_blank">arXiv</a>.</td></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">Jan, 2021: The PieAPP dataset is now available publicly! See <a href="https://github.com/prashnani/PerceptualImageError/blob/master/dataset/dataset_README.md" style="color:528B8B" target="_blank">
				here</a> for details. </td></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">Jul, 2019: Started my internship at Nvidia Research, Learning and Perception Research team.</td></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">Jul, 2019: Secured a compute grant on Google Cloud Platform for our research on deep perceptual metrics for images and videos (through Google Cloud for Startups, Surge).</td></tr><tr></tr><tr></tr>
		    		<tr><td width="100%" align="Left">May, 2019: Outstanding Teaching Assistant award by the ECE department at UCSB.</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">Jun, 2018: Our CVPR2018 paper about a new <a href="https://prashnani.github.io/index_files/Prashnani_CVPR_2018_PieAPP_paper.pdf" style="color:528B8B" target="_blank">
				perceptual image-error metric (PieAPPv0.1)</a> 
				and the associated <a href="https://github.com/prashnani/PerceptualImageError" style="color:528B8B" target="_blank">source code and trained model</a> 
				is now available online! Also, more information can be found on the <a href="http://civc.ucsb.edu/graphics/Papers/CVPR2018_PieAPP/" style="color:528B8B" target="_blank">
				project webpage</a>.</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">May, 2018: Outstanding Teaching Assistant award by the ECE department at UCSB.</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">Apr, 2018: Google travel grant for CVPR2018.</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">Feb, 2018: Our paper "PieAPP: Perceptual Image-Error Assessment through Pairwise Preference" <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/3483.html" style="color:528B8B" target="_blank">is accepted to CVPR 2018.</a>. Code, trained models, and paper coming online soon!</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">Feb, 2018: Our patent on <a href="https://patents.google.com/patent/US20170178301A1/" style="color:528B8B" target="_blank">Single Image Rectification</a> (filed for the work I did during my internship at Ricoh Innovations) is granted!</td></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">Oct, 2017: <a href="https://medium.com/ai-grant/new-ai-grant-fellows-43f1c26c13d9" style="color:528B8B" target="_blank">AI Grant fellowship</a> for developing a perceptually-consistent image error metric.</td></tr><tr></tr><tr></tr>
			</tbody>
		</table> 
        <hr size="1" align="left" color="c3c3c3">   		
		
		<font face= "Century Gothic, CenturyGothic, AppleGothic, sans-serif" style="font-size: 22pt;"> Publications
		<table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody>
				<tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">E. Prashnani*, H. Cai*, Y. Mostofi and P. Sen, "PieAPP: Perceptual Image-Error 
					Assessment through Pairwise Preference," <em> Computer Vision and Pattern Recognition, 2018.</em> <br> <center>
					[<a href="http://civc.ucsb.edu/graphics/Papers/CVPR2018_PieAPP/" style="color:528B8B">project webpage</a>] 
					[<a href="https://arxiv.org/abs/1806.02067v1" style="color:528B8B">paper</a>]														
					[<a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/3483-supp.pdf" style="color:528B8B">supplementary</a>]					
					[<a href="https://prashnani.github.io/index_files/Prashnani_CVPR_2018_PieAPP_poster.pdf" style="color:528B8B">poster</a>]					
					[<a href="https://github.com/prashnani/PerceptualImageError" style="color:528B8B">source code</a>]
					[<a href="https://github.com/prashnani/PerceptualImageError/blob/master/dataset/dataset_README.md" style="color:528B8B">dataset</a>]					
					[<a href="https://www.ece.ucsb.edu/~ekta/projects/PieAPPv0.1/PieAPPv0.1_win64_exe.zip" style="color:528B8B">.exe</a>]</center>
				<p><center>
				<img width="100%" src="index_files/teaser_PieAPPv0.1.png" border="0" ></center>
				</p>
				
				</td></tr>
				<tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<tr><td width="100%" align="Left">E. Prashnani, M. Moorkami, D. Vaquero and P. Sen, "A Phase-Based Approach for Animating Images Using Video Examples," <em> Computer Graphics Forum, August 2016, Volume 36,
Issue 6.</em> 
				<center>[<a href="http://onlinelibrary.wiley.com/doi/10.1111/cgf.12940/abstract"  style="color:528B8B" target="_blank">paper</a>] 
				[<a href="https://youtu.be/qaItuwdh1Rw"  style="color:528B8B" target="_blank">video results</a>] </center>
				</td></tr>
				<tr></tr>
				<tr></tr>
				<tr><td width="100%" align="Left"><small>*joint first authors</td></tr>
			</tbody>
		</table> 
        <hr size="1" align="left" color="c3c3c3">    

		<font face= "Century Gothic, CenturyGothic, AppleGothic, sans-serif" style="font-size: 22pt;" id="teaching"> Teaching 
		<table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody>
				<tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<td width="40%" align="center">                    
                    <img width="80%" src="index_files/capstone2019.jpg" border="0" >
                </td>
				<td align="Left">Technical Mentorship for EE Capstone (2018-2019)<br>
				<br><font style="font-size: 11pt;">Provided technical mentorship to seniors on their 
					EE Capstone projects (total five capstone projects).
<br>I worked very closely with the capstone team (left to right in the top picture: Benjamin Hirt, Erik Rosten, Shan-Wei Sun) working on  
<a href="https://capstone.engineering.ucsb.edu/projects/arthrex-autoscribe"  style="color:528B8B" target="_blank">the design and deployment of machine-learning-based 
medical image recognition algorithms for arthroscopic images</a> (sponsored by Arthrex). The team used an Nvidia Jetson TX2 interfaced with the live camera feed from 
an Arthrex surgical drawer, to deploy the trained deep-learning-based models. Check out a brief live demo 
<a href="https://www.youtube.com/watch?time_continue=1&v=U-643GFKFdY&feature=emb_logo"  style="color:528B8B" target="_blank">here</a> (starting at 25s). </font></td></tr>
			</tbody>
		</table>
		<br>			
		<table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody>
				<tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<td width="40%" align="center">                    
                    <img width="80%" src="index_files/capstone_2017_2018.jpg" border="0" >
                </td>
				<td align="Left">Technical Mentorship for EE Capstone (2017-2018)<br>
				<br><font style="font-size: 11pt;">Provided technical mentorship to seniors on their 
					EE Capstone projects (total five capstone projects).
<br>I worked very closely with the capstone team working on  
<a href="https://capstone.engineering.ucsb.edu/projects/arthrex-arthroscout"  style="color:528B8B" target="_blank">medical image recognition 
for arthroscopic images</a> (sponsored by Arthrex). The team (left to right: Jonathan Huynh, 
Phanitta Chomsinsap, Jacob Kurtz and Alae Amara) was selected to present their 
work at the <a href="https://capstone.engineering.ucsb.edu/events/edx2018"  style="color:528B8B" target="_blank">Engineering Design Expo, 2018</a>, at UCSB.</font></td></tr>
			</tbody>
		</table>
		<br>
		<table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<td width="40%" align="center">                    
                    <img width="90%" src="index_files/summer_mentorship_2017.png" border="0" >
                </td>
				<td align="Left">Research Mentor for High School Students (July 2017)<br> 
				<br><font style="font-size: 11pt;"> In the Summer of 2017, I had the opportunity to mentor 
				four exceptional high school students (left to right in first picture: Sohini Kar, Jungwoo Park, Joshua Doolan, James Wang)
				as a part of the <a href="http://www.summer.ucsb.edu/pre-college/research-mentorship-program-rmp"  style="color:528B8B" target="_blank">
				Summer Research Mentorship Program at UCSB</a>. 
				<br>I spent the first few weeks of the program teaching relevant concepts of computer vision and 
				machine learning to these students (they followed along easily - the age for brilliance keeps getting younger!). 
				The students spent the latter half of the program working on the research tasks I designed for them 
				in applying deep learning to object detection (for Sohini and Jungwoo) 
				and image restoration (for Joshua and James).</font></td></tr>
			</tbody>
		</table>
		<br>		
		<table style="font-size: 13pt;" border="0" width="100%" font size="3">
            <tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr>
				<td width="40%" align="center">                    
                    <img width="80%" src="index_files/capstone_2016_2017.jpg" border="0" >
                </td>
				<td align="Left">Technical Mentorship for EE Capstone (2016-2017)<br> 
				<br><font style="font-size: 11pt;">Provided technical mentorship to seniors on their EE Capstone projects (total six capstone projects).
I worked very closely with the capstone team working on 
<a href="https://capstone.engineering.ucsb.edu/projects/flir-pxtal	"  style="color:528B8B" target="_blank">deep-learning-based image super-resolution</a> (sponsored by Flir). 
<br>The team (left to right: Julian Castro, Connor Northend, Jose Jimenez) ended 
up winning the award for the Best Technical Capstone Project!</font></td></tr>
			</tbody>
		</table>
		<br>
		
		
		<hr size="1" align="left" color="c3c3c3"><center>
		<font style="font-size: 11pt;">
		I can also be found on: <a href='https://www.linkedin.com/in/ektaprashnani/' style="color:528B8B" target="_blank">[LinkedIn]</a>
		<a href='https://github.com/prashnani' style="color:528B8B" target="_blank">[Github]</a>
		<a href='https://scholar.google.com/citations?user=na-Ba1EAAAAJ&hl=en' style="color:528B8B" target="_blank">[Google Scholar]</a>
		<a href='https://www.flickr.com/photos/133729196@N03/' style="color:528B8B" target="_blank">[Flickr]</a>
		<a href='https://twitter.com/ekta_prashnani' style="color:528B8B" target="_blank">[Twitter]</a>
		</font></center>
		<hr size="1" align="left" color="c3c3c3">
		
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120416137-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-120416137-1');
</script>

            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div>

<!-- UNCOMMENT THE FOLLOWING TO GIVE CREDIT: -->
<!--  <p><font style="font-size: 11pt;" color="c1c1c1"> <center><a href='https://prashnani.github.io' style="color:c3c3c3">
website template credit: https://prashnani.github.io</a></center></font></p>  -->
</body></html>

